{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging, sys, os, config\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.indices.query.query_transform.base import StepDecomposeQueryTransform\n",
    "from llama_index import LLMPredictor\n",
    "from llama_index.query_engine.multistep_query_engine import MultiStepQueryEngine\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from openlimit import CompletionRateLimiter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see link for details\n",
    "https://gpt-index.readthedocs.io/en/stable/examples/vector_stores/SimpleIndexDemoLlama2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activate OpenAI\n",
    "os.environ['OPENAI_API_KEY']=config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "#Load Index\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"indexNews.json\")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The documents contain information about the Firm's financial statements, including the Glossary of Common Terms and Acronyms, the Notes, and the description of the clients and principal products and services of each of the Firm's business segments. It also includes information about the Firm's accounting policies, acquisitions, cash and cash equivalents, fair values, fair value option, and principal accountant fees and services. Additionally, the documents contain forward-looking statements about the Firm's future trends of revenues, expenses, and net income.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "#It is better in JSON (or XML) so it could be better processed by the future code to write a word document. #nope fuck that\n",
    "response = query_engine.query(\n",
    "    \"Summarize what is in the documents \")\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String saved to response_str_20230812195750.txt\n"
     ]
    }
   ],
   "source": [
    "# text=response.get_formatted_sources() \n",
    "# print((text))\n",
    "word=response.response\n",
    "source=response.source_nodes\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def string_save(outputstr):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    folder_path='Response String'\n",
    "    filename = f'response_str_{timestamp}.txt'\n",
    "    full_path = os.path.join(folder_path, filename)\n",
    "    with open(full_path, 'w') as file:\n",
    "        file.write(outputstr)\n",
    "    return filename\n",
    "\n",
    "filename = string_save(word)\n",
    "print(f\"String saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinAnna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
